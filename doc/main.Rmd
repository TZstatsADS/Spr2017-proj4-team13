---
title: "Project 4 -  Main Script"
author: "Boxuan Zhao, Zixuan Guan, Zheren Tang, Yingxin Zhang, Jihan Wei"
date: "3/22/2017"
output: 
  pdf_document: 
    latex_engine: xelatex
---
#ABSTRACT

In this project, our team was assigned two papers that proposed two algorithms concerning name disambiguations and we implmented these two algorithms in R code and we have also proposed evaluation methods to compare these algorithms. Throughout the process of this project, we have observed several interesting trends. In this file, we will present our data reading, preporcessing, algorithm implements as well as evaluation results.


## Step 0: Load the packages, specify directories

```{r}
##########################################################################################################
# Here replace it with your own path or manually set it in RStudio to the lib folder                     #
setwd("D:/Columbia University/Spring2017-Applied Data Science/Project_4_Bz2290/Spr2017-proj4-team13/lib")#
##########################################################################################################

#Relevant packages
list.of.packages = c("expm","pacman","text2vec","stringr")

new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]

if(length(new.packages))
{
  install.packages(new.packages)
}

library("expm")
library("pacman")
library("text2vec")
library("stringr")
```

## Step 1: Load and process the data

For each record in the dataset, there are some information we want to extract and store: canonical author id, coauthors, paper title, publication venue title. 
In our main.rmd file, you will find our programs for input of each data file which have been proprocessed by our functions stored in "dataclean.R" under the lib folder.

```{r}
#Preprocess our data files
source("../lib/dataclean.R")
#Read in our data files
source("../lib/dataInput.R")
```

## Step 2: Feature design

Following the section 3.1 in the paper, we want to use paper titles to design features for citations. As the notation used in the paper, we want to find a $m$-dimensional citation vector $\alpha_i$ for each citation $i$, $i=1,...,n$. In this dataset, $n=$ `r nrow(AKumar)`. We study "TF-IDF" (term frequency-inverse document frequency) as suggested in the paper.

TF-IDF is a numerical statistics that is intended to reflect how important a word is to a document in a collection or corpus. It is often used as a weighting factor in information retrieval, text mining, and user modeling. The TF-IDF value increases proportionally to the number of times a word appears in the document, but is offset by the frequency of the word in the corpus, which helps to adjust for the fact that some words appear more frequently in general.

$$
\begin{aligned}
\mbox{TF}(t) &=\frac{\mbox{Number of times term $t$ appears in a document}}{\mbox{Total number of terms in the document}}\\
\mbox{IDF}(t) &=\log{\frac{\mbox{Total number of documents}}{\mbox{Number of documents with term $t$ in it}}}\\
\mbox{TF-IDF}(t) &=\mbox{TF}(t)\times\mbox{IDF}(t)
\end{aligned}
$$

For Paper 3
Construct our feature design for paper 3 with resepct to Coauthor, Title and Journal

```{r}
source("../lib/paper3/TFIDF_FeatureDesign.R")
#For paper 3
author_name <- list(AGupta,AKumar,CChen,DJohnson,JLee,JMartin,JRobinson,
                    JSmith,KTanaka,MBrown,MJones,MMiller,SLee,YChen)
coauthor <- list()
paper <- list()
journal <- list()
for(i in 1:14){
  coauthor[[i]] <- Create_Coauthor(author_name[[i]])
  paper[[i]] <- Create_Title(author_name[[i]])
  journal[[i]] <- Create_Journal(author_name[[i]])
  
}
```

For Paper 6
```{r}

```



## Step 3: Clustering

First of all, we perofrom the spectral cluster with QR decomposition on the data sets
```{r}
source("../lib/paper3/Spectral ClusterQR.R")

spec_coauthor <- list()
spec_title <- list()
spec_journal <- list()
for(i in 1:14){
  spec_coauthor[[i]] <- Spectral.Cluster(my.dat = coauthor[[i]],n.cluster = length(unique(author_name[[i]]$AuthorID)))
  spec_title[[i]] <- Spectral.Cluster(my.dat = paper[[i]],n.cluster = length(unique(author_name[[i]]$AuthorID)))
  spec_journal[[i]] <- Spectral.Cluster(my.dat = journal[[i]],n.cluster = length(unique(author_name[[i]]$AuthorID)))
}

```

Second of all, we implememnt the algorithm from paper 6 to analysis our data set. 
```{r}

```

## Step 4: Evaluation

The evaluation will be two fold, the first part of our evaluation will be base on the perfomrance of our model in paper 3 using different features(i.e. coauthor, paper, and jounral). We applied the evaluation based on the following methods:

Let $M$ be the set of machine-generated clusters, and $G$ the set of gold standard clusters. Then. in the table, for example, $a$ is the number of pairs of entities that are assigned to the same cluster in each of $M$ and $G$. Hence, $a$ and $d$ are interpreted as agreements, and $b$ and $c$ disagreements. When the table is considered as a confusion matrix for a two-class prediction problem, the standard "Precision", "Recall","F1", and "Accuracy" are defined as follows.

$$
\begin{aligned}
\mbox{Precision} &=\frac{a}{a+b}\\
\mbox{Recall}&=\frac{a}{a+c}\\
\mbox{F1} &=\frac{2\times\mbox{Precision}\times\mbox{Recall}}{\mbox{Precision}+\mbox{Recall}}\\
\mbox{Accuracy}&=\frac{a+d}{a+b+c+d}
\end{aligned}
$$
```{r}
source('../lib/evaluation_measures.R')

spec_eva <- function(author,result){
  matching <- matching_matrix(author$AuthorID,result)
  perform <- performance_statistics(matching)
  return(as.data.frame(perform))
}

eva_df <- data.frame()

for(i in 1:14){
  eva_df <- rbind(eva_df,spec_eva(author_name[[i]],spec_coauthor[[i]]))
  eva_df <- rbind(eva_df,spec_eva(author_name[[i]],spec_title[[i]]))
  eva_df <- rbind(eva_df,spec_eva(author_name[[i]],spec_journal[[i]]))
}


rownames(eva_df) <- c("AGupta_coauthor","AGupta_paper","AGupta_journal",
                      "AKumar_coauthor","AKumar_paper","AKumar_journal",
                      "CChen_coauthor","CChen_paper","CChen_journal",
                      "DJohnson_coauthor","DJohnson_paper","DJohnson_journal",
                      "JLee_coauthor","JLee_paper","JLee_journal",
                      "JMartin_coauthor","JMartin_paper","JMartin_journal",
                      "JRobinson_coauthor","JRobinson_paper","JRobinson_journal",
                      "JSmith_coauthor","JSmith_paper","JSmith_journal",
                      "KTanaka_coauthor","KTanaka_paper","KTanaka_journal",
                      "MBrown_coauthor","MBrown_paper","MBrown_journal",
                      "MJones_coauthor","MJones_paper","MJones_journal",
                      "MMiller_coauthor","MMiller_paper","MMiller_journal",
                      "SLee_coauthor","SLee_paper","SLee_journal",
                      "YChen_coauthor","YChen_paper","YChen_journal")
write.csv(eva_df, file = "../output/paper3/eva.csv")
```
```{r}
eva_df
```
Then we implement the code we written from paper 6 for the evaluation
```{r}

```


Then we start to compare the two papers using same evaluation methods. Since we do not want to produce a length report, we only use some of the data set to demonstrate what we foud during the development of this project

First of all, we compare two algorithms using each of the three feautres(Coauthor, Paper, Journal) using AKumar data set:

####AKumar data set results:
![Figure 1: Evaluation results](../figs/AKumar_Comparasion3.png)

From the above graph, we can observe that:

Then, we also compare the two algorithm using a different data set KTanaka:

####KTanaka data set results:
![Figure 2: Evaluation results](../figs/KTanaka_Comparasion3.png)

From the above graph, we can see that:

We also have compared the two algorithms using all features:

####JMartin data set results:
![Figure 3: Evaluation results](../figs/JMartin_Comparasion.png)

####MBrown data set results:
![Figure 4: Evaluation results](../figs/MBrown_Comparasion.png)

From the above two graphs, we can see that:

#Step 5 Further Observations of methods in paper 6

In addition to the above evaluation, we have also observed several interesting trends for algorithm introduced in paper 6 using c2 constraint.

####Interesting results cont'd:
![Figure 6: Interesting results](../figs/weight tuning results for paper 6.png)




####Interesting results cont'd:
![Figure 6: Interesting results](../figs/Scaled_vs_Unscaled_X.png)

####Interesting results cont'd:
![Figure 7: Interesting results](../figs/Weigt_0vs1.png)









