---
title: "Project 4 -  Main Script"
author: "Boxuan Zhao, Zixuan Guan, Zheren Tang, Yingxin Zhang, Jihan Wei"
date: "3/22/2017"
output: 
  pdf_document: 
    latex_engine: xelatex
---
#ABSTRACT

In this project, our team was assigned two papers that proposed two algorithms concerning name disambiguations and we implmented these two algorithms in R code and we have also proposed evaluation methods to compare these algorithms. Throughout the process of this project, we have observed several interesting trends. In this file, we will present our data reading, preporcessing, algorithm implements as well as evaluation results.


## Step 0: Load the packages, specify directories

```{r}
##########################################################################################################
# Here replace it with your own path or manually set it in RStudio to the lib folder                     #
setwd("D:/Columbia University/Spring2017-Applied Data Science/Project_4_Bz2290/Spr2017-proj4-team13/lib")#
##########################################################################################################

#Relevant packages
list.of.packages = c("expm","pacman","text2vec","stringr")

new.packages = list.of.packages[!(list.of.packages %in% install.packages()[,"Package"])]

if(length(new.packages))
{
  install.packages(new.packages)
}

library("expm")
library("pacman")
library("text2vec")
library("stringr")
```

## Step 1: Load and process the data

For each record in the dataset, there are some information we want to extract and store: canonical author id, coauthors, paper title, publication venue title. 
In our main.rmd file, you will find our programs for input of each data file which have been proprocessed by our functions stored in "dataclean.R" under the lib folder.

```{r, echo=TRUE}
#Preprocess our data files
source("../lib/dataclean.R")
#Read in our data files
source("../lib/dataInput.R")
```

## Step 2: Feature design

Following the section 3.1 in the paper, we want to use paper titles to design features for citations. As the notation used in the paper, we want to find a $m$-dimensional citation vector $\alpha_i$ for each citation $i$, $i=1,...,n$. In this dataset, $n=$ `r nrow(AKumar)`. We study "TF-IDF" (term frequency-inverse document frequency) as suggested in the paper.

TF-IDF is a numerical statistics that is intended to reflect how important a word is to a document in a collection or corpus. It is often used as a weighting factor in information retrieval, text mining, and user modeling. The TF-IDF value increases proportionally to the number of times a word appears in the document, but is offset by the frequency of the word in the corpus, which helps to adjust for the fact that some words appear more frequently in general.

$$
\begin{aligned}
\mbox{TF}(t) &=\frac{\mbox{Number of times term $t$ appears in a document}}{\mbox{Total number of terms in the document}}\\
\mbox{IDF}(t) &=\log{\frac{\mbox{Total number of documents}}{\mbox{Number of documents with term $t$ in it}}}\\
\mbox{TF-IDF}(t) &=\mbox{TF}(t)\times\mbox{IDF}(t)
\end{aligned}
$$

For Paper 3
Construct our feature design for paper 3 with resepct to Coauthor, Title and Journal

```{r}
source("../lib/paper3/TFIDF_FeatureDesign.R")
#For paper 3
author_name <- list(AGupta,AKumar,CChen,DJohnson,JLee,JMartin,JRobinson,
                    JSmith,KTanaka,MBrown,MJones,MMiller,SLee,YChen)
coauthor <- list()
paper <- list()
journal <- list()
for(i in 1:14){
  coauthor[[i]] <- Create_Coauthor(author_name[[i]])
  paper[[i]] <- Create_Title(author_name[[i]])
  journal[[i]] <- Create_Journal(author_name[[i]])
  
}
```

For Paper 6
```{r}

```



## Step 3: Clustering

First of all, we perofrom the spectral cluster with QR decomposition on the data sets
```{r}
source("../lib/paper3/Spectral ClusterQR.R")

spec_coauthor <- list()
spec_title <- list()
spec_journal <- list()
for(i in 1:14){
  spec_coauthor[[i]] <- Spectral.Cluster(my.dat = coauthor[[i]],n.cluster = length(unique(author_name[[i]]$AuthorID)))
  spec_title[[i]] <- Spectral.Cluster(my.dat = paper[[i]],n.cluster = length(unique(author_name[[i]]$AuthorID)))
  spec_journal[[i]] <- Spectral.Cluster(my.dat = journal[[i]],n.cluster = length(unique(author_name[[i]]$AuthorID)))
}

```

Second of all, we imlememnt the algorithm from paper 6 to analysis our data set. 
```{r}

```

## Step 4: Evaluation

To evaluate the performance of the method, it is required to calculate the degree of agreement between a set of system-output partitions and a set of true partitions. In general, the agreement between two partitioins is measured for a pair of entities within partitions. The basic unit for which pair-wise agreement is assessed is a pair of entities (authors in our case) which belongs to one of the four cells in the following table (Kang et at.(2009)):

\includegraphics[width=500pt]{matching_matrix.png}

Let $M$ be the set of machine-generated clusters, and $G$ the set of gold standard clusters. Then. in the table, for example, $a$ is the number of pairs of entities that are assigned to the same cluster in each of $M$ and $G$. Hence, $a$ and $d$ are interpreted as agreements, and $b$ and $c$ disagreements. When the table is considered as a confusion matrix for a two-class prediction problem, the standard "Precision", "Recall","F1", and "Accuracy" are defined as follows.

$$
\begin{aligned}
\mbox{Precision} &=\frac{a}{a+b}\\
\mbox{Recall}&=\frac{a}{a+c}\\
\mbox{F1} &=\frac{2\times\mbox{Precision}\times\mbox{Recall}}{\mbox{Precision}+\mbox{Recall}}\\
\mbox{Accuracy}&=\frac{a+d}{a+b+c+d}
\end{aligned}
$$
We first evaluate our algorithm using the gold standard,given the length of the code, we hide the chunk so please refer to our main.rmd for details

For paper 3
```{r, include=FALSE}
source('../lib/evaluation_measures.R')

spec_eva <- function(author,result){
  matching <- matching_matrix(author$AuthorID,result)
  perform <- performance_statistics(matching)
  return(as.data.frame(perform))
}

eva_df <- data.frame()

for(i in 1:14){
  eva_df <- rbind(eva_df,spec_eva(author_name[[i]],spec_coauthor[[i]]))
  eva_df <- rbind(eva_df,spec_eva(author_name[[i]],spec_title[[i]]))
  eva_df <- rbind(eva_df,spec_eva(author_name[[i]],spec_journal[[i]]))
}


rownames(eva_df) <- c("AGupta_coauthor","AGupta_paper","AGupta_journal",
                      "AKumar_coauthor","AKumar_paper","AKumar_journal",
                      "CChen_coauthor","CChen_paper","CChen_journal",
                      "DJohnson_coauthor","DJohnson_paper","DJohnson_journal",
                      "JLee_coauthor","JLee_paper","JLee_journal",
                      "JMartin_coauthor","JMartin_paper","JMartin_journal",
                      "JRobinson_coauthor","JRobinson_paper","JRobinson_journal",
                      "JSmith_coauthor","JSmith_paper","JSmith_journal",
                      "KTanaka_coauthor","KTanaka_paper","KTanaka_journal",
                      "MBrown_coauthor","MBrown_paper","MBrown_journal",
                      "MJones_coauthor","MJones_paper","MJones_journal",
                      "MMiller_coauthor","MMiller_paper","MMiller_journal",
                      "SLee_coauthor","SLee_paper","SLee_journal",
                      "YChen_coauthor","YChen_paper","YChen_journal")
write.csv(eva_df, file = "../output/paper3/eva.csv")
```
```{r}
eva_df
```



For paper 6
```{r}

```

Then we use our own ways to evalute. This method assigns a specific Author ID to each generated clusters by locating the Author ID with the maximum number of appearence in each cluster. Again, due to the lengthy code we have, we choose to hide the code and please refer to our main.rmd for detials.

For paper 3
```{r}
source("../lib/paper3/Misclassification.R")

coauthor_mis <- vector()
title_mis <- vector()
journal_mis <- vector()

for(i in 1:14){
  coauthor_mis[i] <- Misclassification(author_name[[i]],spec_coauthor[[i]])
  title_mis[i] <- Misclassification(author_name[[i]],spec_title[[i]])
  journal_mis[i] <- Misclassification(author_name[[i]],spec_journal[[i]])
}


error.rate = data.frame(filename = c("AGupta","AKumar","CChen","DJohnson","JLee","JMartin","JRobinson","JSmith","KTanaka","MBrown","MJones","MMiller","SLee","YChen"), Coauthor = coauthor_mis, Journal= journal_mis, Title=title_mis)
write.csv(error.rate, file = "../output/paper3/misclassification.csv")
```
```{r}
error.rate
```


For paper 6
```{r}

```

#Step 5 Further Observations of methods in paper 6
In addition to the above evaluation, we have also observed several interesting trends for algorithm introduced in paper 6 using c2 constraint.
```{r}

```

